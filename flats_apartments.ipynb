{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8EDDKXdUPX/bt//KimTLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namesakenberg/BrickByBrickML/blob/main/flats_apartments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "49o7Hi6R1d8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# done to save the csv to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyGigLws09sb",
        "outputId": "e9e4151f-27b7-4af7-cbe2-aa111b7731e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "City = 'chandigarh'\n"
      ],
      "metadata": {
        "id": "bSN73efy7Xjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\n",
        "    'authority': 'www.99acres.com',\n",
        "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "    'accept-language': 'en-US,en;q=0.9',\n",
        "    'cache-control': 'no-cache',\n",
        "    'dnt': '1',\n",
        "    'pragma': 'no-cache',\n",
        "    'referer': f'https://www.99acres.com/flats-in-{City}-ffid-page',\n",
        "    'sec-ch-ua': '\"Chromium\";v=\"107\", \"Not;A=Brand\";v=\"8\"',\n",
        "    'sec-ch-ua-mobile': '?0',\n",
        "    'sec-ch-ua-platform': '\"macOS\"',\n",
        "    'sec-fetch-dest': 'document',\n",
        "    'sec-fetch-mode': 'navigate',\n",
        "    'sec-fetch-site': 'same-origin',\n",
        "    'sec-fetch-user': '?1',\n",
        "    'upgrade-insecure-requests': '1',\n",
        "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/527.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36',\n",
        "}\n",
        "\n",
        "# disguise as a human for the website to get the data\n",
        "\n"
      ],
      "metadata": {
        "id": "G-gnA1801wfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the root path\n",
        "root = '/content/drive/MyDrive/capstone_project/Data/City'\n",
        "\n",
        "# List of subfolders to create under City\n",
        "subfolders = ['Flats', 'Societies', 'Residential', 'Independent House']\n",
        "\n",
        "# Loop to create folders\n",
        "for subfolder in subfolders:\n",
        "    path = os.path.join(root, subfolder)\n",
        "    os.makedirs(path, exist_ok=True)  # Creates folder if it doesn't exist\n",
        "\n",
        "print(\"Directory structure created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igUdEvpB3YBc",
        "outputId": "4b731a24-ab3c-489d-9adc-39f510b2ee30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory structure created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"/content/drive/MyDrive/capstone_project/Data/City/Flats/flats_{City}_data-page-{start}-{pageNumber-1}.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X9NJ4rNcd6DG",
        "outputId": "ac3e929b-9cc6-4559-c1aa-2697530116d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/capstone_project/Data/City/Flats/flats_{City}_data-page-{start}-{pageNumber-1}.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put start page number and end page number.\n",
        "\n",
        "# Page number to start extraction data\n",
        "start = int(input(\"Enter page number where you got error in last run.\\nEnter page number to start from:\")) # Starting Page\n",
        "\n",
        "# End Page number- you can change is for start i am taking 10pages at a time,\n",
        "# as IPs are gettig block after some time\n",
        "end = start+10\n",
        "\n",
        "pageNumber = start\n",
        "req=0\n",
        "\n",
        "flats = pd.DataFrame()\n",
        "\n",
        "try :\n",
        "    while pageNumber < end:\n",
        "        i=1\n",
        "        url = f'https://www.99acres.com/flats-in-{City}-ffid-page-{pageNumber}'\n",
        "        page = requests.get(url, headers=headers)\n",
        "        pageSoup = BeautifulSoup(page.content, 'html.parser')\n",
        "        req+=1\n",
        "        for soup in pageSoup.select_one('div[data-label=\"SEARCH\"]').select('section[data-hydration-on-demand=\"true\"]'):\n",
        "\n",
        "        # Extract property name and property sub-name\n",
        "            try:\n",
        "                property_name = soup.select_one('a.srpTuple__propertyName').text.strip()\n",
        "                # Extract link\n",
        "                link = soup.select_one('a.srpTuple__propertyName')['href']\n",
        "                society = soup.select_one('#srp_tuple_society_heading').text.strip()\n",
        "            except:\n",
        "                continue\n",
        "            # Detail Page\n",
        "            page = requests.get(link, headers=headers)\n",
        "            dpageSoup = BeautifulSoup(page.content, 'html.parser')\n",
        "            req += 1\n",
        "            try:\n",
        "                #price Range\n",
        "                price = dpageSoup.select_one('#pdPrice2').text.strip()\n",
        "            except:\n",
        "                price = ''\n",
        "\n",
        "            # Area\n",
        "            try:\n",
        "                area = soup.select_one('#srp_tuple_price_per_unit_area').text.strip()\n",
        "            except:\n",
        "                area =''\n",
        "            # Area with Type\n",
        "            try:\n",
        "                areaWithType = dpageSoup.select_one('#factArea').text.strip()\n",
        "            except:\n",
        "                areaWithType = ''\n",
        "\n",
        "\n",
        "            # Configuration\n",
        "            try:\n",
        "                bedRoom = dpageSoup.select_one('#bedRoomNum').text.strip()\n",
        "            except:\n",
        "                bedRoom = ''\n",
        "            try:\n",
        "                bathroom = dpageSoup.select_one('#bathroomNum').text.strip()\n",
        "            except:\n",
        "                bathroom = ''\n",
        "            try:\n",
        "                balcony = dpageSoup.select_one('#balconyNum').text.strip()\n",
        "            except:\n",
        "                balcony = ''\n",
        "\n",
        "            try:\n",
        "                additionalRoom = dpageSoup.select_one('#additionalRooms').text.strip()\n",
        "            except:\n",
        "                additionalRoom = ''\n",
        "\n",
        "\n",
        "            # Address\n",
        "\n",
        "            try:\n",
        "                address = dpageSoup.select_one('#address').text.strip()\n",
        "            except:\n",
        "                address = ''\n",
        "            # Floor Number\n",
        "            try:\n",
        "                floorNum = dpageSoup.select_one('#floorNumLabel').text.strip()\n",
        "            except:\n",
        "                floorNum = ''\n",
        "\n",
        "            try:\n",
        "                facing = dpageSoup.select_one('#facingLabel').text.strip()\n",
        "            except:\n",
        "                facing = ''\n",
        "\n",
        "            try:\n",
        "                agePossession = dpageSoup.select_one('#agePossessionLbl').text.strip()\n",
        "            except:\n",
        "                agePossession = ''\n",
        "\n",
        "            # Nearby Locations\n",
        "\n",
        "            try:\n",
        "                nearbyLocations = [i.text.strip() for i in dpageSoup.select_one('div.NearByLocation__tagWrap').select('span.NearByLocation__infoText')]\n",
        "            except:\n",
        "                nearbyLocations = ''\n",
        "\n",
        "            # Descriptions\n",
        "            try:\n",
        "                description = dpageSoup.select_one('#description').text.strip()\n",
        "            except:\n",
        "                description = ''\n",
        "\n",
        "            # Furnish Details\n",
        "            try:\n",
        "                furnishDetails = [i.text.strip() for i in dpageSoup.select_one('#FurnishDetails').select('li')]\n",
        "            except:\n",
        "                furnishDetails = ''\n",
        "\n",
        "            # Features\n",
        "            if furnishDetails:\n",
        "                try:\n",
        "                    features = [i.text.strip() for i in dpageSoup.select('#features')[1].select('li')]\n",
        "                except:\n",
        "                    features = ''\n",
        "            else:\n",
        "                try:\n",
        "                    features = [i.text.strip() for i in dpageSoup.select('#features')[0].select('li')]\n",
        "                except:\n",
        "                    features = ''\n",
        "\n",
        "\n",
        "\n",
        "            # Rating by Features\n",
        "            try:\n",
        "                rating = [i.text for i in dpageSoup.select_one('div.review__rightSide>div>ul>li>div').select('div.ratingByFeature__circleWrap')]\n",
        "            except:\n",
        "                rating = ''\n",
        "            # print(top_f)\n",
        "\n",
        "            try:\n",
        "                # Property ID\n",
        "                property_id = dpageSoup.select_one('#Prop_Id').text.strip()\n",
        "            except:\n",
        "                property_id = ''\n",
        "\n",
        "            # Create a dictionary with the given variables\n",
        "            property_data = {\n",
        "            'property_name': property_name,\n",
        "            'link': link,\n",
        "            'society': society,\n",
        "            'price': price,\n",
        "            'area': area,\n",
        "            'areaWithType': areaWithType,\n",
        "            'bedRoom': bedRoom,\n",
        "            'bathroom': bathroom,\n",
        "            'balcony': balcony,\n",
        "            'additionalRoom': additionalRoom,\n",
        "            'address': address,\n",
        "            'floorNum': floorNum,\n",
        "            'facing': facing,\n",
        "            'agePossession': agePossession,\n",
        "            'nearbyLocations': nearbyLocations,\n",
        "            'description': description,\n",
        "            'furnishDetails': furnishDetails,\n",
        "            'features': features,\n",
        "            'rating': rating,\n",
        "            'property_id': property_id\n",
        "        }\n",
        "\n",
        "\n",
        "            temp_df = pd.DataFrame.from_records([property_data])\n",
        "            # print(temp_df)\n",
        "            flats = pd.concat([flats, temp_df], ignore_index=True)\n",
        "            i += 1\n",
        "            # if os.path.isfile(csv_file):\n",
        "            # # Append DataFrame to the existing file without header\n",
        "            #     temp_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
        "            # else:\n",
        "            #     # Write DataFrame to the file with header\n",
        "            #     temp_df.to_csv(csv_file, mode='a', header=True, index=False)\n",
        "\n",
        "            if req % 4==0:\n",
        "                time.sleep(10)\n",
        "            if req % 15 == 0:\n",
        "                time.sleep(50)\n",
        "        print(f'{pageNumber} -> {i}')\n",
        "        pageNumber += 1\n",
        "\n",
        "except AttributeError as e:\n",
        "    print(e)\n",
        "    print(\"----------------\")\n",
        "    print(\"\"\"Your IP might have blocked. Delete Runitme and reconnect again with updating start page number.\\n\n",
        "            You would see in output above like 1 -> 15\\ and so 1 is page number and 15 is data items extracted.\"\"\")\n",
        "    csv_file_path = f\"/content/drive/MyDrive/capstone_project/Data/City/Independent House/flats_{City}_data-page-{start}-{pageNumber-1}.csv\"\n",
        "\n",
        "    # This file will be new every time if start page will chnage, but still taking here mode as append\n",
        "    if os.path.isfile(csv_file_path):\n",
        "    # Append DataFrame to the existing file without header\n",
        "        flats.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        # Write DataFrame to the file with header - first time write\n",
        "        flats.to_csv(csv_file_path, mode='a', header=True, index=False)\n"
      ],
      "metadata": {
        "id": "6xCvFOug5tfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to combine multiple csv file is one file.\n",
        "\n",
        "def combine_csv_files(folder_path, combined_file_path):\n",
        "    combined_data = pd.DataFrame()  # Create an empty DataFrame to hold the combined data\n",
        "\n",
        "    # Iterate through all CSV files in the folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            print('file_path')\n",
        "            # Read the data from the current CSV file\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # Append the data to the combined DataFrame\n",
        "            combined_data = combined_data.append(df, ignore_index=True)\n",
        "\n",
        "            # Delete the original CSV file\n",
        "            os.remove(file_path)\n",
        "\n",
        "    # Save the combined data to a new CSV file\n",
        "    combined_data.to_csv(combined_file_path, index=False)\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Replace with the actual folder path\n",
        "folder_path = '/content/drive/MyDrive/capstone_project/Data/City/Flats'\n",
        "\n",
        "# Replace with the desired combined file path\n",
        "combined_file_path = '/content/drive/MyDrive/capstone_project/Data/City/Flats/combined_flats_data.csv'\n",
        "\n",
        "combine_csv_files(folder_path, combined_file_path)\n"
      ],
      "metadata": {
        "id": "K-wkHm1fRFp1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}